# Copyright (C) 2024 Machine Learning Lab of the University of Oldenburg.
# Licensed under the Academic Free License version 3.0

from __future__ import annotations

import h5py
import numpy as np
from pathlib import Path

import vamm


def find_new_name(path: str | Path) -> Path:
    """
    Find a new name for a file to avoid overwriting an existing file.

    This function takes a path and a name and returns a new name for a file
    that doesn't overwrite an existing file in the given path. The new name is
    generated by adding a incremental suffix.

    Parameters
    ----------
    path : str or Path
        Path where the file will be saved.
    name : str
        Desired name for the file.

    Returns
    -------
    Path
        Path with new name for the file.
    """
    root, name, counter = path.parent, path.stem, 0
    while True:
        if not Path(root, name).with_suffix(".h5").is_file():
            return Path(root, name).with_suffix(".h5")
        else:
            name = f"{path.stem}_{counter}"
            counter += 1


_all_parameter_names = ["prior", "means", "variance", "A", "pies"]
_all_attribute_names = ["covariance_type", "distance"]


def save_params(
    model,
    path: str | Path = "model.h5",
    overwrite: bool = False,
    verbose: bool = False,
) -> None:
    """
    Save model parameters to a file.

    Parameters of components that got discarded will not be saved.

    Parameters
    ----------
    model :
        Save the parameters of this model.
    path : str or Path, optional
        Path to the file. Suffix can be omitted. Defaults to "model.h5".
    overwrite : bool, optional
        Whether to overwrite the file if it already exists. If not, a suffix will be
        added if the file already exists. Defaults to False.
    verbose : bool, optional
        Whether to print verbose messages. Defaults to False.

    Returns
    -------
    None
    """
    path = Path(path).with_suffix(".h5")
    path.parent.mkdir(parents=True, exist_ok=True)
    file = path if overwrite else find_new_name(path)

    # model parameters
    params = {}
    for param_name in _all_parameter_names:
        if hasattr(model, param_name):
            params[param_name] = getattr(model, param_name)[model.mask]

    # class name and other meta data
    model_name = type(model).__name__
    attributes = {"model": model_name}
    for attribute_name in _all_attribute_names:
        if hasattr(model, attribute_name):
            attributes[attribute_name] = getattr(model, attribute_name)

    # adjust shape of variance for GMMs
    covariance_type = attributes.get("covariance_type", None)
    if covariance_type in ("isotropic",):
        params["variance"] = np.array([params["variance"][0, 0]])
    if covariance_type in ("diagonaltied", "mfatied"):
        params["variance"] = params["variance"][0, :]

    # save as h5
    with h5py.File(file, "w") as f:
        for key, value in params.items():
            # kwargs = {"compression": "gzip"} if type(value) == np.ndarray else {}
            f.create_dataset(key, data=value, compression="gzip")
        for key, value in attributes.items():
            f.attrs[key] = value

    if verbose:
        print(f"Model parameters are stored in '{file}'", flush=True)


def load_params(
    path: str | Path = "model.h5",
    C: int | slice | list[int] = slice(None),
    verbose: bool = False,
    **kwargs,
):
    """
    Load model parameters from a file and initialize a new object with these parameters.

    Parameters
    ----------
    path : str or Path, optional
        Path to the file containing the model parameters. Defaults to "model.h5".
    C : int, slice or List[int], optional
        Index or slice specifying which components to load. Defaults to all components.
    verbose : bool, optional
        Whether to print verbose messages. Defaults to False.
    **kwargs
        Additional keyword arguments to initialize the new object.

    Returns
    -------
    model
    """
    path = Path(path)

    params = {}
    with h5py.File(path, "r") as f:
        # class name and other meta data
        attributes = {}
        for key in f.attrs.keys():
            attributes[f"{key}"] = f.attrs[key]

        # model parameters
        keys = (key for key in f.keys() if key in _all_parameter_names)
        for key in keys:
            if f[key].shape == (1,):
                params[f"init_{key}"] = f[key]
            else:
                params[f"init_{key}"] = f[key][C]

    model_name = attributes.pop("model", "Gaussian")
    # use mfa as default model for now
    if model_name == "Gaussian" and "covariance_type" not in attributes:
        attributes["covariance_type"] = "mfa"
    Model = getattr(vamm, model_name)

    if "init_pies" in params:
        # fix name for prior (for older files)
        params["init_prior"] = params.pop("init_pies")

    params["init_prior"] /= params["init_prior"].sum()  # fix prior

    mask = params["init_prior"] != 0.0
    if not mask.all():
        for key, item in params.items():
            if item.shape != (1,):
                params[key] = item[mask]

    C, D = params["init_means"].shape  # all models have means (so far)
    params |= {"C": C, "D": D}

    if "init_A" in params:
        params["H"] = params["init_A"].shape[2]

    params |= attributes

    params |= kwargs
    model = Model(**params)

    if verbose:
        print(
            f"Model parameters of '{model_name}' successfully loaded from '{path}'",
            flush=True,
        )

        if not mask.all():
            print(
                f"Found zero(s) in priors. Discarded {mask.shape[0] - C} component(s)!",
                flush=True,
            )
    return model
